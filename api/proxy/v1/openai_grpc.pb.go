// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.4.0
// - protoc             v5.27.1
// source: proxy/v1/openai.proto

package v1

import (
	context "context"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.62.0 or later.
const _ = grpc.SupportPackageIsVersion8

const (
	OpenAI_ChatCompletion_FullMethodName       = "/proxy.v1.OpenAI/ChatCompletion"
	OpenAI_StreamChatCompletion_FullMethodName = "/proxy.v1.OpenAI/StreamChatCompletion"
)

// OpenAIClient is the client API for OpenAI service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type OpenAIClient interface {
	ChatCompletion(ctx context.Context, in *ChatCompletionRequest, opts ...grpc.CallOption) (*ChatCompletionResponse, error)
	StreamChatCompletion(ctx context.Context, in *StreamChatCompletionRequest, opts ...grpc.CallOption) (OpenAI_StreamChatCompletionClient, error)
}

type openAIClient struct {
	cc grpc.ClientConnInterface
}

func NewOpenAIClient(cc grpc.ClientConnInterface) OpenAIClient {
	return &openAIClient{cc}
}

func (c *openAIClient) ChatCompletion(ctx context.Context, in *ChatCompletionRequest, opts ...grpc.CallOption) (*ChatCompletionResponse, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	out := new(ChatCompletionResponse)
	err := c.cc.Invoke(ctx, OpenAI_ChatCompletion_FullMethodName, in, out, cOpts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *openAIClient) StreamChatCompletion(ctx context.Context, in *StreamChatCompletionRequest, opts ...grpc.CallOption) (OpenAI_StreamChatCompletionClient, error) {
	cOpts := append([]grpc.CallOption{grpc.StaticMethod()}, opts...)
	stream, err := c.cc.NewStream(ctx, &OpenAI_ServiceDesc.Streams[0], OpenAI_StreamChatCompletion_FullMethodName, cOpts...)
	if err != nil {
		return nil, err
	}
	x := &openAIStreamChatCompletionClient{ClientStream: stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type OpenAI_StreamChatCompletionClient interface {
	Recv() (*StreamChatCompletionResponse, error)
	grpc.ClientStream
}

type openAIStreamChatCompletionClient struct {
	grpc.ClientStream
}

func (x *openAIStreamChatCompletionClient) Recv() (*StreamChatCompletionResponse, error) {
	m := new(StreamChatCompletionResponse)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// OpenAIServer is the server API for OpenAI service.
// All implementations must embed UnimplementedOpenAIServer
// for forward compatibility
type OpenAIServer interface {
	ChatCompletion(context.Context, *ChatCompletionRequest) (*ChatCompletionResponse, error)
	StreamChatCompletion(*StreamChatCompletionRequest, OpenAI_StreamChatCompletionServer) error
	mustEmbedUnimplementedOpenAIServer()
}

// UnimplementedOpenAIServer must be embedded to have forward compatible implementations.
type UnimplementedOpenAIServer struct {
}

func (UnimplementedOpenAIServer) ChatCompletion(context.Context, *ChatCompletionRequest) (*ChatCompletionResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method ChatCompletion not implemented")
}
func (UnimplementedOpenAIServer) StreamChatCompletion(*StreamChatCompletionRequest, OpenAI_StreamChatCompletionServer) error {
	return status.Errorf(codes.Unimplemented, "method StreamChatCompletion not implemented")
}
func (UnimplementedOpenAIServer) mustEmbedUnimplementedOpenAIServer() {}

// UnsafeOpenAIServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to OpenAIServer will
// result in compilation errors.
type UnsafeOpenAIServer interface {
	mustEmbedUnimplementedOpenAIServer()
}

func RegisterOpenAIServer(s grpc.ServiceRegistrar, srv OpenAIServer) {
	s.RegisterService(&OpenAI_ServiceDesc, srv)
}

func _OpenAI_ChatCompletion_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ChatCompletionRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(OpenAIServer).ChatCompletion(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: OpenAI_ChatCompletion_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(OpenAIServer).ChatCompletion(ctx, req.(*ChatCompletionRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _OpenAI_StreamChatCompletion_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(StreamChatCompletionRequest)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(OpenAIServer).StreamChatCompletion(m, &openAIStreamChatCompletionServer{ServerStream: stream})
}

type OpenAI_StreamChatCompletionServer interface {
	Send(*StreamChatCompletionResponse) error
	grpc.ServerStream
}

type openAIStreamChatCompletionServer struct {
	grpc.ServerStream
}

func (x *openAIStreamChatCompletionServer) Send(m *StreamChatCompletionResponse) error {
	return x.ServerStream.SendMsg(m)
}

// OpenAI_ServiceDesc is the grpc.ServiceDesc for OpenAI service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var OpenAI_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "proxy.v1.OpenAI",
	HandlerType: (*OpenAIServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "ChatCompletion",
			Handler:    _OpenAI_ChatCompletion_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "StreamChatCompletion",
			Handler:       _OpenAI_StreamChatCompletion_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "proxy/v1/openai.proto",
}
